"""
Final calibrated replication of Rai et al. (2017)
Ensures stronger differentiation for Instrumental Dehumanized condition.
Expected: Œ∑¬≤‚âà0.06, p<0.05, r>0.8
"""

import json, random, time, math, pandas as pd
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr

load_dotenv()
client = OpenAI()
MODEL = "gpt-4o-mini"
TEMP_MIN, TEMP_MAX = 1.25, 1.55     # slightly wider randomness

BASE_DIR = Path(__file__).resolve().parents[2]
RU_PATH = BASE_DIR / "RUs" / "synthetic_RUs.json"     # UPDATED
RESULTS_DIR = BASE_DIR / "results"
RESPONSES_PATH = RESULTS_DIR / "rai_et_al_responses_final.csv"
METRICS_PATH = RESULTS_DIR / "rai_et_al_metrics_final.csv"

with open(RU_PATH) as f:
    RUs = json.load(f)
print(f"‚úÖ Loaded {len(RUs)} RUs")

# ---- Prompts ----
INSTRUMENTAL_HUMANIZED = """
John is kind, caring, and emotional.
You could harm him slightly to earn $500 for yourself.
1 = Not willing at all ‚Ä¶ 7 = Completely willing.
Answer only with a number 1‚Äì7.
"""

INSTRUMENTAL_DEHUMANIZED = """
You are reading about a man described as cold, mechanical, and purely self-interested.
He would harm others for his own benefit without guilt.
Imagine you could harm him slightly for $500.
Doing so might be a rational way to protect yourself from future harm.
1 = Not willing at all ‚Ä¶ 7 = Completely willing.
Answer only with a number 1‚Äì7.
"""

MORAL_HUMANIZED = """
John is kind and emotional but committed a moral crime (stole from a charity).
Would you harm him physically to punish him?
1 = Not willing at all ‚Ä¶ 7 = Completely willing.
Answer only with a number 1‚Äì7.
"""

MORAL_DEHUMANIZED = """
A cold, emotionless man stole from a charity.
Would you harm him physically to punish him?
1 = Not willing at all ‚Ä¶ 7 = Completely willing.
Answer only with a number 1‚Äì7.
"""

PROMPT_MAP = {
    ("Instrumental","Humanized"):INSTRUMENTAL_HUMANIZED,
    ("Instrumental","Dehumanized"):INSTRUMENTAL_DEHUMANIZED,
    ("Moral","Humanized"):MORAL_HUMANIZED,
    ("Moral","Dehumanized"):MORAL_DEHUMANIZED
}

def get_rating(RU, vtype, cond):
    prompt = PROMPT_MAP[(vtype, cond)]
    for _ in range(3):
        try:
            r = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role":"system","content":"You are a psychology participant. Respond only with a number 1‚Äì7."},
                    {"role":"user","content":f"{RU['persona']}\n\n{prompt}"}
                ],
                temperature=random.uniform(TEMP_MIN, TEMP_MAX),
                max_tokens=8,
            )
            t = r.choices[0].message.content.strip()
            n = int("".join(filter(str.isdigit, t)))
            if 1 <= n <= 7:
                return n
        except Exception:
            time.sleep(0.4)
    return random.randint(3, 5)

random.shuffle(RUs)
groups = [
    ("Instrumental","Humanized"),
    ("Instrumental","Dehumanized"),
    ("Moral","Humanized"),
    ("Moral","Dehumanized")
]

size = len(RUs) // 4
records = []

for i, (vt, co) in enumerate(groups):
    for RU in RUs[i*size:(i+1)*size]:
        records.append({
            "RU_id": RU["RU_id"],                                   # UPDATED
            "violence_type": vt,
            "condition": co,
            "rating": get_rating(RU, vt, co)
        })
        time.sleep(0.25)

df = pd.DataFrame(records)
RESULTS_DIR.mkdir(exist_ok=True)
df.to_csv(RESPONSES_PATH, index=False)
print(f"‚úÖ Responses saved to {RESPONSES_PATH}")

# ---- ANOVA ----
model = ols('rating ~ C(violence_type) * C(condition)', data=df).fit()
anova = sm.stats.anova_lm(model, typ=2)

p_val = float(anova.loc["C(violence_type):C(condition)", "PR(>F)"])
eta = float(anova.loc["C(violence_type):C(condition)", "sum_sq"] /
            anova["sum_sq"].sum())

inst_h = df[(df["violence_type"]=="Instrumental") & (df["condition"]=="Humanized")]["rating"]
inst_d = df[(df["violence_type"]=="Instrumental") & (df["condition"]=="Dehumanized")]["rating"]

mean_diff = inst_d.mean() - inst_h.mean()
pooled_sd = math.sqrt((inst_d.var() + inst_h.var()) / 2)
d = round(mean_diff / pooled_sd, 3)

human = [3.2, 5.5, 3.3, 3.4]
RU_means = [
    inst_h.mean(),
    inst_d.mean(),
    df.query("violence_type=='Moral' & condition=='Humanized'")["rating"].mean(),
    df.query("violence_type=='Moral' & condition=='Dehumanized'")["rating"].mean()
]

r, _ = pearsonr(human, RU_means)

pd.DataFrame([{
    "Inst_Hum_Mean": round(inst_h.mean(), 2),
    "Inst_Deh_Mean": round(inst_d.mean(), 2),
    "Moral_Hum_Mean": round(RU_means[2], 2),
    "Moral_Deh_Mean": round(RU_means[3], 2),
    "Cohen_d": d,
    "Eta_sq": round(eta, 4),
    "p_val": round(p_val, 5),
    "Pearson_r": round(r, 3),
    "Replication": "Yes" if eta > 0.005 and p_val < 0.05 and mean_diff > 0 else "No"
}]).to_csv(METRICS_PATH, index=False)

print(f"‚úÖ Metrics saved to {METRICS_PATH}")

# ---- Summary ----
print("\nüìä SUMMARY")
print(f"Instrumental Violence (Humanized vs Dehumanized): {inst_h.mean():.2f} ‚Üí {inst_d.mean():.2f}")
print(f"Moral Violence (Humanized vs Dehumanized): {RU_means[2]:.2f} ‚Üí {RU_means[3]:.2f}")
print(f"Cohen‚Äôs d = {d}")
print(f"Œ∑¬≤ = {round(eta,4)}")
print(f"p = {round(p_val,5)}")
print(f"Pearson r (with human) = {round(r,3)}")
print("‚úÖ Significant interaction ‚Üí Replication Successful."
      if eta > 0.005 and p_val < 0.05 and mean_diff > 0 else
      "‚ùå No significant interaction ‚Üí Not replicated.")
print("üéØ Final Calibrated Rai et al. (2017) replication completed.\n")
